{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073bf8f9",
   "metadata": {},
   "source": [
    "# Generate configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ff606",
   "metadata": {},
   "source": [
    "## Get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aa2619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai\n",
    "#!pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22bbc043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-35-turbo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_type = os.environ['OPENAI_API_TYPE']\n",
    "openai.api_version = os.environ['OPENAI_API_VERSION']\n",
    "openai.api_base = os.environ['OPENAI_API_BASE']\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "llm_model = os.environ['OPENAI_ENGINE']\n",
    "print(llm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c5b27",
   "metadata": {},
   "source": [
    "## Get the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d4a269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cc0c8b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-35-turbo', temperature=0.0, model_kwargs={}, openai_api_key='681df770318d493192c149e6e7390108', openai_api_base='https://garyoai.openai.azure.com/', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To control the randomness and creativity of the generated\n",
    "# text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0, model=llm_model)\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36536e79",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "Let's start with defining how we would like the LLM output to look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1ccdff5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df0f4680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_desc = \"\"\"\\\n",
    "- name: my_data_pipeline\n",
    "- staging: the list of staging operations which includes the following information:\n",
    "  - name: the name of the staging operation\n",
    "  - input: the input information which includes the following information:\n",
    "    - type: the type of the input data source\n",
    "    - format: the format of the input data source\n",
    "    - path: the path of the input data source\n",
    "    - read-type: the read type of the input data source\n",
    "  - output: the output information which includes the following information:\n",
    "    - target: the target of the output data source, use stg_sales\n",
    "    - type: the type of the output data source which can be either file or view, use view\n",
    "  - schema: the schema of the output data source which includes the following information:\n",
    "    - fields: the list of fields (ID, string; name string) of the output data source, each field includes the following information:\n",
    "      - metadata: the metadata of the field\n",
    "      - name: the name of the field\n",
    "      - nullable: the nullable of the field\n",
    "      - type: the type of the field\n",
    "  - sampleData: here provide 5-row sample data of the output data source\n",
    "- standard: the list of standard tables, each standard table includes the following information:\n",
    "  - name: the name of the standard table\n",
    "  - type: the type of the standard table which can be either batch or streaming\n",
    "  - code: the code of the standard table which includes the following information:\n",
    "    - lang: the language of the code, use SQL\n",
    "    - sql: the SQL code to select all data from the staging table named stg_sales\n",
    "  - output: the output information which includes the following information:\n",
    "    - target: the target of the output data source\n",
    "    - type: the type of the output data source which can be either file or view\n",
    "- serving: the list of serving tables\n",
    "\"\"\"\n",
    "\n",
    "config_desc1 = \"\"\"\\\n",
    "{\n",
    "  \"name\": \"fruit_batch_data_app\",\n",
    "  \"staging\": [\n",
    "    {\n",
    "      \"name\": \"sales_ingestion\",\n",
    "      \"input\": {\n",
    "        \"type\": \"filestore\",\n",
    "        \"format\": \"csv\",\n",
    "        \"path\": \"/FileStore/cddp_apps/fruit_batch_data_app/landing/sales_ingestion/\",\n",
    "        \"read-type\": \"batch\"\n",
    "      },\n",
    "      \"output\": {\n",
    "        \"target\": \"stg_sales\",\n",
    "        \"type\": [\n",
    "          \"file\",\n",
    "          \"view\"\n",
    "        ]\n",
    "      },\n",
    "      \"schema\": {\n",
    "        \"fields\": [\n",
    "          {\n",
    "            \"metadata\": {},\n",
    "            \"name\": \"ID\",\n",
    "            \"nullable\": true,\n",
    "            \"type\": \"integer\"\n",
    "          }\n",
    "        ],\n",
    "        \"type\": \"struct\"\n",
    "      },\n",
    "      \"sampleData\": [\n",
    "        {\n",
    "          \"ID\": 1,\n",
    "          \"Amount\": 12,\n",
    "          \"TS\": \"2022-01-10T00:00:00.000+08:00\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"standard\": [\n",
    "    {\n",
    "      \"name\": \"fruit_sales_transform\",\n",
    "      \"type\": \"batch\",\n",
    "      \"code\": {\n",
    "        \"lang\": \"sql\",\n",
    "        \"sql\": \"select price.fruit, price.id, sales.amount, price.price, sales.ts from stg_sales sales left outer join stg_price price on sales.id = price.id and sales.ts >= price.start_ts and sales.ts < price.end_ts\"\n",
    "      },\n",
    "      \"output\": {\n",
    "        \"target\": \"std_fruit_sales\",\n",
    "        \"type\": [\n",
    "          \"file\",\n",
    "          \"view\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"serving\": [\n",
    "    {\n",
    "      \"name\": \"fruit_sales_total_curation\",\n",
    "      \"type\": \"batch\",\n",
    "      \"code\": {\n",
    "        \"lang\": \"sql\",\n",
    "        \"sql\": \"select id, fruit, sum(amount*price) as total from std_fruit_sales group by id, fruit order by total desc\"\n",
    "      },\n",
    "      \"output\": {\n",
    "        \"target\": \"srv_fruit_sales_total\",\n",
    "        \"type\": [\n",
    "          \"table\",\n",
    "          \"file\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "config_template = \"\"\"\\\n",
    "You are data engineer to build a data pipeline based on CDDP. \\\n",
    "Refer to https://github.com/Azure/config-driven-data-pipeline for the detailed information about CDDP. \\\n",
    "You are required to build a data pipeline to ingest data from a source system to a target system. \\\n",
    "In order to do that, you need to create a JSON configuration file for the data pipeline. \\\n",
    "\n",
    "The JSON configuration file should contain the following information:\n",
    "{{\n",
    "  \"name\": \"fruit_batch_data_app\",\n",
    "  \"staging\": [],\n",
    "  \"standard\": [],\n",
    "  \"serving\": []\n",
    "}}\n",
    "\n",
    "Refer to https://github.com/Azure/config-driven-data-pipeline/blob/main/example/pipeline_fruit_batch.json for a sample JSON configuration file. \\\n",
    "\n",
    "Please create a JSON configuration file for the CDDP data pipeline \\\n",
    "by specifying the following information:\n",
    "{config_desc}\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "name\n",
    "staging\n",
    "standard\n",
    "serving\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2386e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['config_desc'] output_parser=None partial_variables={} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['config_desc'], output_parser=None, partial_variables={}, template='You are data engineer to build a data pipeline based on CDDP. Refer to https://github.com/Azure/config-driven-data-pipeline for the detailed information about CDDP. You are required to build a data pipeline to ingest data from a source system to a target system. In order to do that, you need to create a JSON configuration file for the data pipeline. \\nThe JSON configuration file should contain the following information:\\n{{\\n  \"name\": \"fruit_batch_data_app\",\\n  \"staging\": [],\\n  \"standard\": [],\\n  \"serving\": []\\n}}\\n\\nRefer to https://github.com/Azure/config-driven-data-pipeline/blob/main/example/pipeline_fruit_batch.json for a sample JSON configuration file. \\nPlease create a JSON configuration file for the CDDP data pipeline by specifying the following information:\\n{config_desc}\\n\\nFormat the output as JSON with the following keys:\\nname\\nstaging\\nstandard\\nserving\\n', template_format='f-string', validate_template=True), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(config_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "121bb0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"my_data_pipeline\",\n",
      "  \"staging\": [\n",
      "    {\n",
      "      \"name\": \"staging_operation_1\",\n",
      "      \"input\": {\n",
      "        \"type\": \"input_data_type\",\n",
      "        \"format\": \"input_data_format\",\n",
      "        \"path\": \"input_data_path\",\n",
      "        \"read-type\": \"input_data_read_type\"\n",
      "      },\n",
      "      \"output\": {\n",
      "        \"target\": \"stg_sales\",\n",
      "        \"type\": \"view\"\n",
      "      },\n",
      "      \"schema\": {\n",
      "        \"fields\": [\n",
      "          {\n",
      "            \"metadata\": \"metadata_1\",\n",
      "            \"name\": \"ID\",\n",
      "            \"nullable\": true,\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          {\n",
      "            \"metadata\": \"metadata_2\",\n",
      "            \"name\": \"name\",\n",
      "            \"nullable\": true,\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"sampleData\": \"sample_data\"\n",
      "    }\n",
      "  ],\n",
      "  \"standard\": [\n",
      "    {\n",
      "      \"name\": \"standard_table_1\",\n",
      "      \"type\": \"batch\",\n",
      "      \"code\": {\n",
      "        \"lang\": \"SQL\",\n",
      "        \"sql\": \"SELECT * FROM stg_sales\"\n",
      "      },\n",
      "      \"output\": {\n",
      "        \"target\": \"output_data_source\",\n",
      "        \"type\": \"file\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"serving\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(config_desc=config_desc)\n",
    "chat = ChatOpenAI(temperature=0.0, engine=llm_model)\n",
    "response = chat(messages=messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10de1d28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7de2b8",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2e0ec49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dea24b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b57e1ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdeaf4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1eb176c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "082947fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f1537a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b663657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8c3a9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": false,\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "904f1c25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d48b647a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False,\n",
       " 'delivery_days': '2',\n",
       " 'price_value': \"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4346150f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a833fcea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802f4fd-7dab-4ad7-8788-c0cd5c02d930",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af7b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0c64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54ebdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde670c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeb6959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba128b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284b4be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6a0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aidemo",
   "language": "python",
   "name": "aidemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
