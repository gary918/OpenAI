{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMGxBP-yQoCl"
   },
   "source": [
    "# Compare finetuned vs. non-finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "height": 30,
    "id": "PKnPPEyPR3MO"
   },
   "outputs": [],
   "source": [
    "from llama import BasicModelRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Non-Finetuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "non_finetuned = BasicModelRunner(\"meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Invalid token",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/venv/ai/lib/python3.11/site-packages/llama/program/util/run_ai.py:134\u001b[0m, in \u001b[0;36mpowerml_send_query_to_url\u001b[0;34m(params, route)\u001b[0m\n\u001b[1;32m    131\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(\n\u001b[1;32m    132\u001b[0m         url\u001b[39m=\u001b[39murl \u001b[39m+\u001b[39m route, headers\u001b[39m=\u001b[39mheaders, json\u001b[39m=\u001b[39mparams, timeout\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    135\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout:\n",
      "File \u001b[0;32m~/Documents/venv/ai/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://api.powerml.co/v1/llama/run_program",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m non_finetuned_output \u001b[39m=\u001b[39m non_finetuned(\u001b[39m\"\u001b[39;49m\u001b[39mTell me how to train my dog to sit\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/venv/ai/lib/python3.11/site-packages/llama/runners/basic_model_runner.py:50\u001b[0m, in \u001b[0;36mBasicModelRunner.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     \u001b[39m# Singleton\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     input_objects \u001b[39m=\u001b[39m Input(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39minputs)\n\u001b[0;32m---> 50\u001b[0m output_objects \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm(\n\u001b[1;32m     51\u001b[0m     \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49minput_objects,\n\u001b[1;32m     52\u001b[0m     output_type\u001b[39m=\u001b[39;49mOutput,\n\u001b[1;32m     53\u001b[0m     model_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[1;32m     54\u001b[0m     enable_peft\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menable_peft,\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output_objects, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     57\u001b[0m     outputs \u001b[39m=\u001b[39m [o\u001b[39m.\u001b[39moutput \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m output_objects]\n",
      "File \u001b[0;32m~/Documents/venv/ai/lib/python3.11/site-packages/llama/program/builder.py:85\u001b[0m, in \u001b[0;36mBuilder.__call__\u001b[0;34m(self, input, output_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_model(\u001b[39minput\u001b[39m, output_type, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 85\u001b[0m     result \u001b[39m=\u001b[39m gen_value(value)\n\u001b[1;32m     86\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/venv/ai/lib/python3.11/site-packages/llama/program/util/api_actions.py:203\u001b[0m, in \u001b[0;36mgen_value\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen_value\u001b[39m(value: Value):\n\u001b[0;32m--> 203\u001b[0m     value\u001b[39m.\u001b[39;49m_compute_value()\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39m_data\n",
      "File \u001b[0;32m~/Documents/venv/ai/lib/python3.11/site-packages/llama/program/value.py:65\u001b[0m, in \u001b[0;36mValue._compute_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     params \u001b[39m=\u001b[39m {\n\u001b[1;32m     62\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mprogram\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function\u001b[39m.\u001b[39mprogram\u001b[39m.\u001b[39mto_dict(),\n\u001b[1;32m     63\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrequested_values\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index],\n\u001b[1;32m     64\u001b[0m     }\n\u001b[0;32m---> 65\u001b[0m     response \u001b[39m=\u001b[39m query_run_program(params)\n\u001b[1;32m     67\u001b[0m     response\u001b[39m.\u001b[39mraise_for_status()\n\u001b[1;32m     69\u001b[0m     \u001b[39m# update the cache\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/venv/ai/lib/python3.11/site-packages/llama/program/util/run_ai.py:11\u001b[0m, in \u001b[0;36mquery_run_program\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery_run_program\u001b[39m(params):\n\u001b[0;32m---> 11\u001b[0m     resp \u001b[39m=\u001b[39m powerml_send_query_to_url(params, \u001b[39m\"\u001b[39;49m\u001b[39m/v1/llama/run_program\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m     \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Documents/venv/ai/lib/python3.11/site-packages/llama/program/util/run_ai.py:159\u001b[0m, in \u001b[0;36mpowerml_send_query_to_url\u001b[0;34m(params, route)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         json_response \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 159\u001b[0m     \u001b[39mraise\u001b[39;00m llama\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mAuthenticationError(\n\u001b[1;32m    160\u001b[0m         json_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdetail\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAuthenticationError\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m400\u001b[39m:\n\u001b[1;32m    163\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mAuthenticationError\u001b[0m: Invalid token"
     ]
    }
   ],
   "source": [
    "non_finetuned_output = non_finetuned(\"Tell me how to train my dog to sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
    "Customer: I didn't get my item\n",
    "Agent: I'm sorry to hear that. Which item was it?\n",
    "Customer: the blanket\n",
    "Agent:\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to finetuned models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "finetuned_model = BasicModelRunner(\"meta-llama/Llama-2-7b-chat-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "finetuned_output = finetuned_model(\"Tell me how to train my dog to sit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(non_finetuned(\"[INST]Tell me how to train my dog to sit[/INST]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"What do you think of Mars?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"taylor swift's best friend\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "print(finetuned_model(\"\"\"Agent: I'm here to help you with your Amazon deliver order.\n",
    "Customer: I didn't get my item\n",
    "Agent: I'm sorry to hear that. Which item was it?\n",
    "Customer: the blanket\n",
    "Agent:\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "chatgpt = BasicModelRunner(\"chat-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(chatgpt(\"Tell me how to train my dog to sit\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "aidemo",
   "language": "python",
   "name": "aidemo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
